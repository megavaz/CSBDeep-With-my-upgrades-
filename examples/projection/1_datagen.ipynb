{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Demo: Training data generation for joint denoising and surface projection of *Drosophila melanogaster* wing\n",
    "\n",
    "This notebook demonstrates training data generation for a 3D â†’ 2D denoising+projection task, where corresponding pairs of low and high quality 3D stacks can be acquired. The surface of interest is then extracted from the high quality stacks with a conventional projection method, such as [PreMosa](https://doi.org/10.1093/bioinformatics/btx195).\n",
    "\n",
    "More documentation is available at http://csbdeep.bioimagecomputing.com/doc/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import download_and_extract_zip_file, plot_some\n",
    "from csbdeep.data import RawData, create_patches_reduced_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Download example data\n",
    "\n",
    "First we download some example data, consisting of low-SNR 3D stacks with corresponding 2D surface images extracted from the high-SNR stacks.  \n",
    "Note that `GT` stands for [ground truth](https://en.wikipedia.org/wiki/Ground_truth) and represents high signal-to-noise ratio (SNR) images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_and_extract_zip_file (\n",
    "    url       = 'http://csbdeep.bioimagecomputing.com/example_data/flywing.zip',\n",
    "    targetdir = 'data',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot one of the training pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = imread('data/flywing/GT/session_4_P08.tif')\n",
    "x = imread('data/flywing/low_C0/session_4_P08.tif')\n",
    "print('input  image size =', x.shape)\n",
    "print('output image size =', y.shape)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plot_some(np.stack([x,np.broadcast_to(y,x.shape)]),\n",
    "          title_list=[['low-SNR stack (maximum projection)','high-SNR (surface extracted with PreMosa)']], \n",
    "          pmin=2,pmax=99.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Generate training data for denoising + projection CARE\n",
    "\n",
    "We first need to create a `RawData` object, which defines how to get the pairs of low/high SNR images and the semantics of each axis (e.g. which one is considered a color channel, etc.).\n",
    "\n",
    "Here we have several folders with low-SNR images and one folder \"GT\" with the high-SNR extracted surface images. Note that corresponding images are TIFF files with identical names.  \n",
    "For this case, we use `RawData.from_folder` and set `axes = 'ZYX'` to indicate the semantic axes of the low-SNR input stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData.from_folder (\n",
    "    basepath    = 'data/flywing',\n",
    "    source_dirs = ['low_C0','low_C2','low_C3'],\n",
    "    target_dir  = 'GT',\n",
    "    axes        = 'ZYX',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From corresponding images, we now generate some 3D/2D patches. As a general rule, use a `patch_size` that is a power of two along all non-channel axes, here at least divisible by 16. You can use `None` along the projection axis (typically `Z`, i.e. use `reduction_axes = 'Z'`) to indicate that each patch should contain the entire image along this axis.\n",
    "Furthermore, set `target_axes` appropriately if the target images are missing the projection axis.\n",
    "\n",
    "Note that returned values `(X, Y, XY_axes)` by `create_patches_reduced_target` are not to be confused with the image axes X and Y.  \n",
    "By convention, the variable name `X` (or `x`) refers to an input variable for a machine learning model, whereas `Y` (or `y`) indicates an output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, XY_axes = create_patches_reduced_target (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (None,128,128),\n",
    "    n_patches_per_image = 16,\n",
    "    target_axes         = 'YX',\n",
    "    reduction_axes      = 'Z',\n",
    "    save_file           = 'data/my_training_data.npz',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of X   =\", X.shape)\n",
    "print(\"shape of Y   =\", Y.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show\n",
    "\n",
    "This shows some of the generated patch pairs (odd rows: maximum projection of *source*, even rows: *target*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1)), 0\n",
    "    plot_some(X[sl],Y[sl],title_list=[np.arange(sl[0].start,sl[0].stop)])\n",
    "    plt.show()\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
