{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Demo: Training data generation for combined denoising and upsamling of synthetic 3D data\n",
    "\n",
    "This notebook demonstrates training data generation for a combined denoising and upsampling task of synthetic 3D data, where corresponding pairs of isotropic low and high quality stacks can be acquired.\n",
    "Anisotropic distortions along the Z axis will be simulated for the low quality stack, such that a CARE model trained on this data can be applied to images with anisotropic resolution along Z.\n",
    "\n",
    "We will use only a few synthetically generated stacks for training data generation, whereas in your application you should aim to use stacks from different developmental timepoints to ensure a well trained model. \n",
    "\n",
    "More documentation is available at http://csbdeep.bioimagecomputing.com/doc/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import download_and_extract_zip_file, plot_some, axes_dict\n",
    "from csbdeep.io import save_training_data\n",
    "from csbdeep.data import RawData, create_patches\n",
    "from csbdeep.data.transform import anisotropic_distortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Download example data\n",
    "\n",
    "First we download some example data, consisting of a synthetic 3D stacks with membrane-like structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_zip_file (\n",
    "    url       = 'http://csbdeep.bioimagecomputing.com/example_data/synthetic_upsampling.zip',\n",
    "    targetdir = 'data',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot XY and XZ slices of a training stack pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = imread('data/synthetic_upsampling/training_stacks/high/stack_00.tif')\n",
    "x = imread('data/synthetic_upsampling/training_stacks/low/stack_00.tif')\n",
    "print('image size =', x.shape)\n",
    "\n",
    "plt.figure(figsize=(16,15))\n",
    "plot_some(np.stack([x[5],y[5]]),\n",
    "          title_list=[['XY slice (low)','XY slice (high)']],\n",
    "          pmin=2,pmax=99.8);\n",
    "\n",
    "plt.figure(figsize=(16,15))\n",
    "plot_some(np.stack([np.moveaxis(x,1,0)[50],np.moveaxis(y,1,0)[50]]),\n",
    "          title_list=[['XZ slice (low)','XZ slice (high)']],\n",
    "          pmin=2,pmax=99.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Generate training data for upsampling CARE\n",
    "\n",
    "We first need to create a `RawData` object, which defines how to get the pairs of low/high SNR stacks and the semantics of each axis (e.g. which one is considered a color channel, etc.).\n",
    "\n",
    "Here we have two folders \"low\" and \"high\", where corresponding low and high-SNR stacks are TIFF images with identical filenames.  \n",
    "For this case, we can simply use `RawData.from_folder` and set `axes = 'ZYX'` to indicate the semantic order of the image axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData.from_folder (\n",
    "    basepath    = 'data/synthetic_upsampling/training_stacks',\n",
    "    source_dirs = ['low'],\n",
    "    target_dir  = 'high',\n",
    "    axes        = 'ZYX',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we must define how to modify the Z axis to mimic a real microscope as closely as possible if data along this axis is acquired with reduced resolution. To that end, we define a `Transform` object that will take our `RawData` as input and return the modified image. Here, we use `anisotropic_distortions` to accomplish this.\n",
    "\n",
    "The most important parameter is the subsampling factor along Z, which should for example be chosen as 4 if it is planned to later acquire (low-SNR) images with 4 times reduced axial resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anisotropic_transform = anisotropic_distortions (\n",
    "    subsample      = 4,\n",
    "    psf            = None,\n",
    "    subsample_axis = 'Z',\n",
    "    yield_target   = 'target',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the synthetically undersampled low quality input stack and its corresponding high quality stack, we now generate some 3D patches. As a general rule, use a patch size that is a power of two along XYZT, or at least divisible by 8.  \n",
    "Typically, you should use more patches the more trainings stacks you have. By default, patches are sampled from non-background regions (i.e. that are above a relative threshold), see the documentation of `create_patches` for details.\n",
    "\n",
    "Note that returned values `(X, Y, XY_axes)` by `create_patches` are not to be confused with the image axes X and Y.  \n",
    "By convention, the variable name `X` (or `x`) refers to an input variable for a machine learning model, whereas `Y` (or `y`) indicates an output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, XY_axes = create_patches (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (32,64,64),\n",
    "    n_patches_per_image = 512,\n",
    "    transforms          = [anisotropic_transform],\n",
    "    save_file           = 'data/my_training_data.npz',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == Y.shape\n",
    "print(\"shape of X,Y =\", X.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show\n",
    "\n",
    "This shows a ZY slice of some of the generated patch pairs (odd rows: *source*, even rows: *target*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,2))\n",
    "    sl = slice(8*i, 8*(i+1)), slice(None), slice(None), 0\n",
    "    plot_some(X[sl],Y[sl],title_list=[np.arange(sl[0].start,sl[0].stop)])\n",
    "    plt.show()\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
