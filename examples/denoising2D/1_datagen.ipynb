{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Demo: Denoising of 2D cell images\n",
    "\n",
    "This notebook demonstrates training data generation for a 2D denoising task, where corresponding pairs of low and high quality images can be acquired.\n",
    "\n",
    "The high SNR images are acquistions of Human U2OS cells taken from the [Broad Bioimage Benchmark Collection](https://data.broadinstitute.org/bbbc/BBBC006/) and the low SNR images were created by synthetically adding *strong read-out and shot-noise* (and additionally applying *pixel binning* of 2x2) thus mimicking acquisitions at a very low light level.  \n",
    "\n",
    "![](imgs/denoising_binning_overview.png)\n",
    "\n",
    "Each image pair should be registered, which in a real application setting is best achieved by acquiring both images _interleaved_, i.e. as different channels that correspond to the different exposure/laser settings. \n",
    "Since the image pairs were synthetically created in this example, they are already perfectly aligned.\n",
    "\n",
    "More documentation is available at http://csbdeep.bioimagecomputing.com/doc/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import download_and_extract_zip_file, plot_some\n",
    "from csbdeep.data import RawData, create_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Example data\n",
    "\n",
    "The example data consists of low-SNR and high-SNR 2D images of human U2OS cells.  \n",
    "Note that `GT` stands for [ground truth](https://en.wikipedia.org/wiki/Ground_truth) and represents high signal-to-noise ratio (SNR) stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_zip_file (\n",
    "    url       = 'http://csbdeep.bioimagecomputing.com/example_data/snr_7_binning_2.zip',\n",
    "    targetdir = 'data',\n",
    "    verbose   = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is already split into a **train** and **test** set, each containing low SNR (\"low\") and corresponding high SNR (\"GT\") images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot some training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = imread('data/train/GT/img_0010.tif')\n",
    "x = imread('data/train/low/img_0010.tif')\n",
    "print('image size =', x.shape)\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x, cmap  =\"magma\")\n",
    "plt.colorbar()\n",
    "plt.title(\"low\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(y, cmap  =\"magma\")\n",
    "plt.colorbar()\n",
    "plt.title(\"high\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Generate training data for CARE\n",
    "\n",
    "We first need to create a `RawData` object, which defines how to get the pairs of low/high SNR images and the semantics of each axis (e.g. which one is considered a color channel, etc.).\n",
    "\n",
    "Here we have two folders \"low\" and \"GT\", where corresponding low and high-SNR TIFF images have identical filenames.  \n",
    "For this case, we can simply use `RawData.from_folder` and set `axes = 'YX'` to indicate the semantic order of the image axes (i.e. we have typical 2 dimensional images). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData.from_folder (\n",
    "    basepath    = 'data/train',\n",
    "    source_dirs = ['low'],\n",
    "    target_dir  = 'GT',\n",
    "    axes        = 'YX',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From corresponding images, the function `create_patches` will now generate lots of paired patches that will be used for training the CARE model later.\n",
    "\n",
    "`create_patches` returns values `(X, Y, XY_axes)`.\n",
    "By convention, the variable name `X` (or `x`) refers to an input variable for a machine learning model, whereas `Y` (or `y`) indicates an output variable.\n",
    "\n",
    "As a general rule, use a *patch size* that is a power of two along all axes, or which is at least divisible by 8. For this example we will use patches of size 128x128.\n",
    "\n",
    "An important aspect is *data normalization*, i.e. the rescaling of corresponding patches to a dynamic range of ~ (0,1). By default, this is automatically provided via percentile normalization, which can be adapted if needed. \n",
    "\n",
    "By default, patches are sampled from *non-background regions* i.e. that are above a relative threshold that can be given in the function below. We will disable this for this dataset as most image regions already contain foreground pixels and thus set the threshold to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.data import no_background_patches, norm_percentiles, sample_percentiles\n",
    "\n",
    "X, Y, XY_axes = create_patches (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (128,128),\n",
    "    patch_filter        = no_background_patches(0),\n",
    "    n_patches_per_image = 2,\n",
    "    save_file           = 'data/my_training_data.npz',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == Y.shape\n",
    "print(\"shape of X,Y =\", X.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some example patches\n",
    "\n",
    "This shows some of the generated patch pairs (even rows: *input*, odd rows: *target*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1)), 0\n",
    "    plot_some(X[sl],Y[sl],title_list=[np.arange(sl[0].start,sl[0].stop)])\n",
    "    plt.show()\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
