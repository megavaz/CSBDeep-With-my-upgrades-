{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Demo: Training data generation for denoising of *Tribolium castaneum*\n",
    "\n",
    "This notebook demonstrates training data generation for a 3D denoising task, where corresponding pairs of low and high quality stacks can be acquired. \n",
    "\n",
    "Each pair should be registered, which is best achieved by acquiring both stacks _interleaved_, i.e. as different channels that correspond to the different exposure/laser settings. \n",
    "\n",
    "We will use a single Tribolium stack pair for training data generation, whereas in your application you should aim to acquire at least 10-50 stacks from different developmental timepoints to ensure a well trained model. \n",
    "\n",
    "More documentation is available at http://csbdeep.bioimagecomputing.com/doc/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import download_and_extract_zip_file, plot_some\n",
    "from csbdeep.data import RawData, create_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Download example data\n",
    "\n",
    "First we download some example data, consisting of low-SNR and high-SNR 3D images of Tribolium.  \n",
    "Note that `GT` stands for [ground truth](https://en.wikipedia.org/wiki/Ground_truth) and represents high signal-to-noise ratio (SNR) stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_zip_file (\n",
    "    url       = 'http://csbdeep.bioimagecomputing.com/example_data/tribolium.zip',\n",
    "    targetdir = 'data',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the training stack pair via maximum-projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = imread('data/tribolium/train/GT/nGFP_0.1_0.2_0.5_20_13_late.tif')\n",
    "x = imread('data/tribolium/train/low/nGFP_0.1_0.2_0.5_20_13_late.tif')\n",
    "print('image size =', x.shape)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plot_some(np.stack([x,y]),\n",
    "          title_list=[['low (maximum projection)','GT (maximum projection)']], \n",
    "          pmin=2,pmax=99.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Generate training data for CARE\n",
    "\n",
    "We first need to create a `RawData` object, which defines how to get the pairs of low/high SNR stacks and the semantics of each axis (e.g. which one is considered a color channel, etc.).\n",
    "\n",
    "Here we have two folders \"low\" and \"GT\", where corresponding low and high-SNR stacks are TIFF images with identical filenames.  \n",
    "For this case, we can simply use `RawData.from_folder` and set `axes = 'ZYX'` to indicate the semantic order of the image axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData.from_folder (\n",
    "    basepath    = 'data/tribolium/train',\n",
    "    source_dirs = ['low'],\n",
    "    target_dir  = 'GT',\n",
    "    axes        = 'ZYX',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From corresponding stacks, we now generate some 3D patches. As a general rule, use a patch size that is a power of two along XYZT, or at least divisible by 8.  \n",
    "Typically, you should use more patches the more trainings stacks you have. By default, patches are sampled from non-background regions (i.e. that are above a relative threshold), see the documentation of `create_patches` for details.\n",
    "\n",
    "Note that returned values `(X, Y, XY_axes)` by `create_patches` are not to be confused with the image axes X and Y.  \n",
    "By convention, the variable name `X` (or `x`) refers to an input variable for a machine learning model, whereas `Y` (or `y`) indicates an output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, XY_axes = create_patches (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (16,64,64),\n",
    "    n_patches_per_image = 1024,\n",
    "    save_file           = 'data/my_training_data.npz',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == Y.shape\n",
    "print(\"shape of X,Y =\", X.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show\n",
    "\n",
    "This shows the maximum projection of some of the generated patch pairs (odd rows: *source*, even rows: *target*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1)), 0\n",
    "    plot_some(X[sl],Y[sl],title_list=[np.arange(sl[0].start,sl[0].stop)])\n",
    "    plt.show()\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
